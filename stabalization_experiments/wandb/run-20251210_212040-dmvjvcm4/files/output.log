[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
INFO:__main__:Loading and processing datasets...
INFO:data_processing:Loading MBPP dataset...
INFO:data_processing:Original MBPP columns: ['task_id', 'text', 'code', 'test_list', 'test_setup_code', 'challenge_test_list']
INFO:data_processing:Original MBPP size: 974
INFO:data_processing:Processed MBPP columns: ['prompt', 'completion']
INFO:data_processing:Processed MBPP size: 974
INFO:data_processing:Loading APPS dataset...
INFO:data_processing:Original APPS columns: ['problem_id', 'question', 'solutions', 'input_output', 'difficulty', 'url', 'starter_code']
INFO:data_processing:Original APPS size: 5000
INFO:data_processing:Processed APPS columns: ['prompt', 'ground_truth']
INFO:data_processing:Processed APPS size: 5000
INFO:data_processing:Loading APPS dataset from apps_cccs.json...
INFO:data_processing:Original APPS size: 7413
INFO:data_processing:Original APPS columns: ['prompt', 'ground_truth']
Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7413/7413 [00:00<00:00, 340045.23 examples/s]
INFO:data_processing:Processed APPS columns: ['prompt', 'ground_truth']
INFO:data_processing:Processed APPS size: 7413
INFO:__main__:MBPP dataset size: 974
INFO:__main__:APPS dataset size: 5000
INFO:__main__:==================================================
INFO:__main__:Starting SFT Warmup Training
INFO:__main__:==================================================
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                        | 38/155 [02:18<08:33,  4.39s/it]Traceback (most recent call last):
{'loss': 0.7128, 'grad_norm': 5.151431560516357, 'learning_rate': 1.8838709677419354e-05, 'entropy': 1.0372863709926605, 'num_tokens': 25193.0, 'mean_token_accuracy': 0.8128619372844696, 'epoch': 0.32}
{'loss': 0.6688, 'grad_norm': 4.699287414550781, 'learning_rate': 1.7548387096774196e-05, 'entropy': 1.05137939453125, 'num_tokens': 47455.0, 'mean_token_accuracy': 0.8167490661144257, 'epoch': 0.65}
{'loss': 0.6601, 'grad_norm': 3.5556633472442627, 'learning_rate': 1.6258064516129034e-05, 'entropy': 1.100926297903061, 'num_tokens': 69822.0, 'mean_token_accuracy': 0.8193441331386566, 'epoch': 0.97}
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 397, in <module>
    main()
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 365, in main
    sft_model_path = run_sft_warmup(
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 197, in run_sft_warmup
    trainer.train()
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 1190, in training_step
    return super().training_step(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 1151, in compute_loss
    shift_logits = outputs.logits[..., :-1, :].contiguous()
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.31 GiB. GPU 0 has a total capacity of 47.53 GiB of which 6.54 GiB is free. Including non-PyTorch memory, this process has 40.97 GiB memory in use. Of the allocated memory 39.92 GiB is allocated by PyTorch, and 745.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 397, in <module>
    main()
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 365, in main
    sft_model_path = run_sft_warmup(
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 197, in run_sft_warmup
    trainer.train()
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 1190, in training_step
    return super().training_step(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 1151, in compute_loss
    shift_logits = outputs.logits[..., :-1, :].contiguous()
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.31 GiB. GPU 0 has a total capacity of 47.53 GiB of which 6.54 GiB is free. Including non-PyTorch memory, this process has 40.97 GiB memory in use. Of the allocated memory 39.92 GiB is allocated by PyTorch, and 745.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
