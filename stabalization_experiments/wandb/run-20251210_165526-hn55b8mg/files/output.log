[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
INFO:__main__:Loading and processing datasets...
INFO:data_processing:Loading MBPP dataset...
INFO:data_processing:Original MBPP columns: ['task_id', 'text', 'code', 'test_list', 'test_setup_code', 'challenge_test_list']
INFO:data_processing:Original MBPP size: 974
INFO:data_processing:Processed MBPP columns: ['prompt', 'completion']
INFO:data_processing:Processed MBPP size: 9
INFO:data_processing:Loading APPS dataset...
INFO:data_processing:Original APPS columns: ['problem_id', 'question', 'solutions', 'input_output', 'difficulty', 'url', 'starter_code']
INFO:data_processing:Original APPS size: 5000
INFO:data_processing:Processed APPS columns: ['prompt', 'completion']
INFO:data_processing:Processed APPS size: 50
INFO:__main__:MBPP dataset size: 9
INFO:__main__:APPS dataset size: 50
INFO:__main__:==================================================
INFO:__main__:Starting SFT Warmup Training
INFO:__main__:==================================================
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:27<00:00,  3.03s/it]
{'train_runtime': 27.2616, 'train_samples_per_second': 0.33, 'train_steps_per_second': 0.33, 'train_loss': 0.7007355160183377, 'entropy': 1.0465453267097473, 'num_tokens': 693.0, 'mean_token_accuracy': 0.7641757726669312, 'epoch': 1.0}
INFO:__main__:SFT model saved to ./outputs/sft_checkpoint
INFO:__main__:==================================================
INFO:__main__:Starting GRPO Training
INFO:__main__:==================================================
Traceback (most recent call last):
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 347, in <module>
    main()
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 328, in main
    run_grpo_training(
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 195, in run_grpo_training
    grpo_config = GRPOConfig(
  File "<string>", line 185, in __init__
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_config.py", line 719, in __post_init__
    raise ValueError(
ValueError: generation_batch_size (1) must be divisible by num_generations (8).
Traceback (most recent call last):
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 347, in <module>
    main()
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 328, in main
    run_grpo_training(
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 195, in run_grpo_training
    grpo_config = GRPOConfig(
  File "<string>", line 185, in __init__
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_config.py", line 719, in __post_init__
    raise ValueError(
ValueError: generation_batch_size (1) must be divisible by num_generations (8).
