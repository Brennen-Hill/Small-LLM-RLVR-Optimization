[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
INFO:__main__:Loading and processing datasets...
INFO:data_processing:Loading MBPP dataset...
INFO:data_processing:Original MBPP columns: ['task_id', 'text', 'code', 'test_list', 'test_setup_code', 'challenge_test_list']
INFO:data_processing:Original MBPP size: 974
INFO:data_processing:Processed MBPP columns: ['prompt', 'ground_truth']
INFO:data_processing:Processed MBPP size: 9
INFO:data_processing:Loading APPS dataset...
INFO:data_processing:Original APPS columns: ['problem_id', 'question', 'solutions', 'input_output', 'difficulty', 'url', 'starter_code']
INFO:data_processing:Original APPS size: 5000
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00<00:00, 5734.25 examples/s]
Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00<00:00, 145862.45 examples/s]
INFO:data_processing:Processed APPS columns: ['prompt', 'ground_truth']
INFO:data_processing:Processed APPS size: 50
Dataset({
    features: ['prompt', 'ground_truth'],
    num_rows: 50
})
INFO:__main__:MBPP dataset size: 9
INFO:__main__:APPS dataset size: 50
INFO:__main__:Skipping SFT warmup, using base model for GRPO
INFO:__main__:==================================================
INFO:__main__:Starting GRPO Training
INFO:__main__:==================================================
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
  2%|â–ˆâ–‰                                                                                               | 3/150 [00:20<17:40,  7.21s/it]Traceback (most recent call last):
{'completion_ids': [[576, 4396, 6291, 686, 387, 2686, 1091, 220, 16, 15, 82, 624, 334, 97611, 106185, 1019, 13874, 3989, 947, 38636, 14778, 284, 729, 320, 1118, 317, 262, 1077, 2790, 284, 220, 15, 280, 262, 421, 320, 1118, 621, 845, 340, 262, 341, 286, 470, 220, 15, 280, 262, 456, 262, 369, 320, 1149, 600, 284, 220, 15, 26, 600, 27, 2890, 13, 3084, 26, 600, 3485, 262, 341, 286, 2790, 1421, 4149, 14572, 10939, 989, 60, 481, 2890, 989, 488, 16, 2558, 262, 456, 73594, 256, 220, 104465, 4149, 14572, 2075, 69515, 80158, 100710, 118274, 101149, 3837, 104689, 102173, 104552, 118274, 3837, 107525, 99796, 3407, 334, 100005, 46100, 1019, 13874, 3989, 947, 38636, 14778, 284, 729, 320, 1653, 8, 341, 262, 1077, 2790, 284, 220, 15, 280, 262, 369, 320, 1149, 600, 284, 220, 15, 26, 600, 27, 1334, 1954, 26, 600, 3485, 262, 341, 286, 2790, 488, 1334, 989, 60, 481, 1334, 989, 488, 16, 935, 262, 456, 262, 470, 2790, 280, 2440, 73594, 151643], [4354, 421, 697, 4688, 5221, 432, 1290, 369, 678, 315, 1493, 498, 686, 1083, 5258, 8311, 6668, 369, 3281, 12037, 7032, 382, 39, 3221, 25, 61830, 7132, 504, 6422, 311, 6422, 53724, 498, 279, 1852, 2783, 438, 43084, 11450, 25165, 39296, 382, 565, 12478, 220, 16, 320, 18, 14, 18, 15, 7731, 262, 762, 38636, 14778, 284, 729, 38502, 1072, 8, 314, 198, 262, 762, 6010, 284, 220, 15, 26, 198, 262, 369, 320, 762, 600, 284, 220, 15, 26, 600, 366, 458, 1072, 1954, 481, 220, 16, 26, 600, 2457, 314, 5872, 286, 6010, 1421, 4149, 14572, 38502, 1072, 989, 60, 481, 458, 1072, 989, 488, 220, 16, 2546, 262, 456, 262, 470, 6010, 198, 262, 555, 565, 12478, 220, 17, 320, 16, 14, 18, 15, 7731, 262, 729, 38636, 14778, 6110, 8, 341, 2405, 6010, 284, 220, 15, 280, 1572, 2023, 7537, 600, 284, 220, 15, 26, 600, 366, 1334, 1954, 26, 600, 6796, 197, 98052, 1421, 4149, 14572, 1956, 481, 320, 1653, 1954, 481, 220, 16, 1106, 197, 532, 853, 6010, 26, 715, 262, 335, 151643]], 'trainer_state': TrainerState(epoch=0, global_step=0, max_steps=150, logging_steps=10, eval_steps=500, save_steps=500, train_batch_size=2, num_train_epochs=3, num_input_tokens_seen=747, total_flos=0, log_history=[], best_metric=None, best_global_step=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})}
{'completion_ids': [[11, 9339, 0, 758, 88444, 5510, 320, 2152, 8310, 10602, 3623, 44987, 20028, 9533, 61716, 8, 508, 46, 71719, 9533, 46, 71719, 8, 508, 840, 20772, 21324, 9533, 840, 20772, 21324, 8, 508, 69769, 9533, 69769, 21324, 340, 4418, 508, 69769, 21324, 9533, 69769, 21324, 8, 311, 7225, 3535, 279, 3491, 320, 98361, 15629, 8129, 4292, 32622, 19762, 12, 9801, 9533, 33, 19762, 12, 9801, 21324, 340, 32622, 19762, 12, 9801, 9533, 33, 19762, 12, 9801, 21324, 8, 198, 7661, 356, 8129, 1588, 25, 508, 1782, 2038, 48796, 57920, 448, 7299, 1273, 23910, 9533, 2428, 1110, 1851, 48796, 905, 14, 65717, 14, 16, 21, 18, 17, 37885, 2728, 14, 16, 18, 20, 23, 18, 17, 20, 21, 23, 692, 18300, 356, 14223, 73594, 66, 198, 1067, 366, 66922, 397, 1067, 366, 41078, 397, 1067, 366, 3215, 1339, 322, 5029, 595, 220, 15, 8203, 74, 27, 16, 15, 15, 7493, 6422, 5969, 10569, 322, 7192, 897, 595, 2651, 308, 366, 595, 353, 308, 271, 322, 470, 549, 55129, 1372, 304, 279, 8500, 271, 3626, 1293, 1293, 282, 12266, 1293, 1293, 595, 11, 3774, 1293, 1293, 308, 8, 198, 515, 262, 442, 902, 22901, 198, 262, 2060, 5969, 2651, 220, 16, 15, 15, 43, 317, 262, 2060, 1445, 366, 1460, 486, 19600, 31820, 26354, 1293, 1293, 6831, 2810, 5231, 262, 3774, 1293, 1293, 12981, 284, 220, 16, 401, 262, 369, 12266, 1293, 1293, 600, 284, 595, 26, 600, 366, 308, 26, 600, 1421, 595, 340, 262, 341, 286, 12981, 1421, 282, 5969, 11, 600, 608, 595, 317, 262], [549, 3623, 2, 7684, 15019, 0, 1597, 30169, 1862, 421, 498, 1521, 432, 6133, 0, 4710, 8420, 374, 264, 2086, 61688, 16445, 264, 4428, 8500, 448, 1008, 16982, 11, 2598, 508, 16704, 884, 9533, 2428, 1110, 4987, 68, 8479, 5071, 79997, 28, 20, 19, 22, 340, 3973, 700, 279, 7286, 315, 2847, 27509, 1588, 25, 508, 16704, 27509, 5251, 587, 10134, 13002, 337, 91504, 7658, 5262, 1457, 17, 19, 60, 4710, 58, 16, 5669, 3703, 1110, 72, 22420, 55277, 905, 38151, 87, 351, 74, 3508, 198, 58, 17, 5669, 3703, 1110, 72, 22420, 55277, 905, 31082, 42, 74, 20, 22, 3508, 198, 58, 18, 5669, 3703, 1110, 72, 22420, 55277, 905, 7530, 75, 22, 18, 48, 3508, 198, 58, 19, 5669, 3703, 1110, 72, 22420, 55277, 905, 26491, 17, 78, 72150, 3508, 198, 58, 20, 5669, 3703, 1110, 72, 22420, 55277, 905, 14, 4817, 23, 84, 21, 3508, 198, 58, 21, 5669, 3703, 1110, 72, 22420, 55277, 905, 14, 3067, 72, 22681, 3508, 198, 58, 22, 5669, 3703, 1110, 72, 22420, 55277, 905, 14, 5863, 72, 17, 40, 3508, 198, 58, 23, 5669, 3703, 1110, 72, 22420, 55277, 905, 5523, 57, 13545, 16, 3508, 198, 58, 24, 5669, 3703, 1110, 72, 22420, 55277, 905, 6663, 18, 21827, 46, 3508, 198, 58, 16, 15, 5669, 3703, 1110, 72, 22420, 55277, 905, 14, 17, 17, 24, 77, 53, 3508, 198, 58, 16, 16, 5669, 3703, 1110, 72, 22420, 55277, 905, 14, 20, 78, 46, 21, 19, 3508, 198, 58, 16, 17, 5669, 3703, 1110, 72, 22420, 55277, 905]], 'trainer_state': TrainerState(epoch=0.02, global_step=1, max_steps=150, logging_steps=10, eval_steps=500, save_steps=500, train_batch_size=2, num_train_epochs=3, num_input_tokens_seen=1755, total_flos=0, log_history=[], best_metric=None, best_global_step=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})}
{'completion_ids': [[198, 198, 1040, 12478, 314, 198, 888, 510, 262, 1807, 374, 2833, 3609, 607, 8, 341, 286, 526, 3668, 4273, 284, 220, 15, 26, 198, 286, 526, 1372, 4273, 284, 220, 15, 280, 286, 526, 1841, 4273, 284, 220, 15, 280, 286, 526, 12756, 4273, 284, 220, 15, 26, 198, 286, 369, 1548, 600, 28, 15, 4696, 27, 495, 1954, 2129, 72, 6796, 310, 421, 4199, 989, 60, 621, 6256, 12298, 394, 12756, 4273, 3507, 310, 456, 310, 770, 421, 9623, 34934, 4199, 989, 58201, 394, 1372, 4273, 3507, 394, 421, 4199, 989, 15825, 15, 7672, 72, 961, 607, 1954, 15694, 16, 8, 3668, 4273, 3507, 310, 456, 310, 770, 421, 9623, 7141, 4199, 989, 58201, 394, 3668, 4273, 3507, 310, 456, 310, 770, 421, 3471, 69829, 4199, 989, 2467, 7672, 495, 989, 60, 961, 6256, 12298, 394, 1438, 26, 198, 310, 456, 310, 421, 40046, 4273, 861, 220, 16, 8, 1438, 280, 1789, 286, 456, 286, 421, 17918, 4273, 621, 220, 15, 8, 470, 895, 26, 198, 1789, 286, 421, 1500, 12597, 4273, 621, 220, 16, 1264, 286, 421, 4199, 989, 60, 621, 6256, 12298, 310, 470, 12756, 4273, 418, 16, 7672, 7752, 4273, 418, 16, 7672, 19190, 4273, 418, 15, 280, 286, 456, 262, 456, 286, 421, 49901, 4273, 861, 220, 15, 8, 470, 895, 280, 286, 421, 40046, 4273, 861, 220, 16, 8, 470, 895, 280, 286, 421, 40046, 4273, 861, 220, 15, 1009, 357, 16106, 43378, 67301, 11172, 4199, 11, 220, 15, 11, 220, 16, 8, 621, 364, 69, 863, 470, 895], [198, 198, 1040, 12478, 341, 888, 510, 262, 1807, 374, 2833, 2741, 1161, 353, 82, 8, 341, 286, 442, 12236, 262, 456, 11061, 151643]], 'trainer_state': TrainerState(epoch=0.04, global_step=2, max_steps=150, logging_steps=10, eval_steps=500, save_steps=500, train_batch_size=2, num_train_epochs=3, num_input_tokens_seen=2277, total_flos=0, log_history=[], best_metric=None, best_global_step=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})}
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 371, in <module>
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 351, in main
    model_name=sft_model_path,
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 236, in run_grpo_training
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2316, in train
    return inner_training_loop(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 4014, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1067, in _prepare_inputs
    generation_batch = self._generate_and_score_completions(generation_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1462, in _generate_and_score_completions
    self._generate(prompts)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1400, in _generate
    prompt_ids, completion_ids, logprobs, extra_fields = self._generate_single_turn(prompts)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1375, in _generate_single_turn
    prompt_completion_ids = unwrapped_model.generate(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2787, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 410, in forward
    hidden_states = decoder_layer(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 260, in forward
    hidden_states, _ = self.self_attn(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 201, in forward
    key_states = self.k_norm(self.k_proj(hidden_states).view(hidden_shape)).transpose(1, 2)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 63, in forward
    hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)
KeyboardInterrupt
Traceback (most recent call last):
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 371, in <module>
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 351, in main
    model_name=sft_model_path,
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 236, in run_grpo_training
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2316, in train
    return inner_training_loop(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 4014, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1067, in _prepare_inputs
    generation_batch = self._generate_and_score_completions(generation_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1462, in _generate_and_score_completions
    self._generate(prompts)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1400, in _generate
    prompt_ids, completion_ids, logprobs, extra_fields = self._generate_single_turn(prompts)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1375, in _generate_single_turn
    prompt_completion_ids = unwrapped_model.generate(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2787, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 480, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 410, in forward
    hidden_states = decoder_layer(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 260, in forward
    hidden_states, _ = self.self_attn(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 201, in forward
    key_states = self.k_norm(self.k_proj(hidden_states).view(hidden_shape)).transpose(1, 2)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 63, in forward
    hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)
KeyboardInterrupt
