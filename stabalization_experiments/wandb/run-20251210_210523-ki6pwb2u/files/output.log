[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
INFO:__main__:Loading and processing datasets...
INFO:data_processing:Loading MBPP dataset...
INFO:data_processing:Original MBPP columns: ['task_id', 'text', 'code', 'test_list', 'test_setup_code', 'challenge_test_list']
INFO:data_processing:Original MBPP size: 974
INFO:data_processing:Processed MBPP columns: ['prompt', 'completion']
INFO:data_processing:Processed MBPP size: 974
INFO:data_processing:Loading APPS dataset...
INFO:data_processing:Original APPS columns: ['problem_id', 'question', 'solutions', 'input_output', 'difficulty', 'url', 'starter_code']
INFO:data_processing:Original APPS size: 5000
INFO:data_processing:Processed APPS columns: ['prompt', 'ground_truth']
INFO:data_processing:Processed APPS size: 5000
INFO:data_processing:Loading APPS dataset from apps_cccs.json...
INFO:data_processing:Original APPS size: 7413
INFO:data_processing:Original APPS columns: ['prompt', 'ground_truth']
Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7413/7413 [00:00<00:00, 330625.74 examples/s]
INFO:data_processing:Processed APPS columns: ['prompt', 'ground_truth']
INFO:data_processing:Processed APPS size: 7413
INFO:__main__:MBPP dataset size: 974
INFO:__main__:APPS dataset size: 5000
INFO:__main__:==================================================
INFO:__main__:Starting SFT Warmup Training
INFO:__main__:==================================================
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                           | 9/155 [00:17<04:22,  1.80s/it]Traceback (most recent call last):
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 397, in <module>
    main()
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 365, in main
    sft_model_path = run_sft_warmup(
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 197, in run_sft_warmup
    trainer.train()
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2679, in _inner_training_loop
    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))
KeyboardInterrupt
Traceback (most recent call last):
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 397, in <module>
    main()
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 365, in main
    sft_model_path = run_sft_warmup(
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single.py", line 197, in run_sft_warmup
    trainer.train()
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2679, in _inner_training_loop
    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))
KeyboardInterrupt
