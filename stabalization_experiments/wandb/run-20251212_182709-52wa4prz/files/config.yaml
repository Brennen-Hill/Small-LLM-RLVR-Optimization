_wandb:
    value:
        cli_version: 0.23.1
        e:
            n754bx8uph1yu0ayoks5tihdtqa9y0pd:
                codePath: eval.py
                codePathLocal: eval.py
                cpu_count: 12
                cpu_count_logical: 24
                cudaVersion: "12.4"
                disk:
                    /:
                        total: "466766602240"
                        used: "436477468672"
                email: twu376@wisc.edu
                executable: /hdd3/albertwu/miniconda3/envs/rlvr/bin/python
                git:
                    commit: a2a052cab232cb3153254922bd1e847a37798332
                    remote: git@github.com:Brennen-Hill/CS839.git
                gpu: NVIDIA RTX A6000
                gpu_count: 2
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 10752
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX A6000
                      uuid: GPU-f521e10d-d7e3-3369-1305-a7494180d1b0
                    - architecture: Ampere
                      cudaCores: 5888
                      memoryTotal: "8589934592"
                      name: NVIDIA GeForce RTX 3070
                      uuid: GPU-59aeb9e1-9077-41b6-fca7-ad6d4c237f6d
                host: fred-desktop-2
                memory:
                    total: "101135749120"
                os: Linux-5.15.0-107-generic-x86_64-with-glibc2.31
                program: /hdd3/albertwu/mini_rlvr/eval.py
                python: CPython 3.10.19
                root: /hdd3/albertwu/mini_rlvr
                startedAt: "2025-12-13T00:27:09.505151Z"
                writerId: n754bx8uph1yu0ayoks5tihdtqa9y0pd
        m: []
        python_version: 3.10.19
        t:
            "1":
                - 1
                - 11
                - 49
                - 51
                - 71
            "2":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 71
            "3":
                - 15
                - 16
            "4": 3.10.19
            "5": 0.23.1
            "6": 4.57.3
            "12": 0.23.1
            "13": linux-x86_64
batch_size:
    value: 1
device:
    value: cuda
max_new_tokens:
    value: 512
model_name:
    value: HuggingFaceAlbert/Qwen3-1.7B-grpo-1765505298
temperature:
    value: 0.2
test_sample_percentage:
    value: 0.1
top_p:
    value: 0.95
