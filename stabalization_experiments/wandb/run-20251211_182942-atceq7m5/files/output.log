[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
INFO:__main__:Loading and processing datasets...
INFO:data_processing_optimized:Loading MBPP dataset...
INFO:data_processing_optimized:Original MBPP columns: ['task_id', 'text', 'code', 'test_list', 'test_setup_code', 'challenge_test_list']
INFO:data_processing_optimized:Original MBPP size: 974
INFO:data_processing_optimized:Processed MBPP columns: ['prompt', 'completion']
INFO:data_processing_optimized:Processed MBPP size: 9
INFO:data_processing_optimized:Loading APPS dataset...
INFO:data_processing_optimized:Original APPS columns: ['problem_id', 'question', 'solutions', 'input_output', 'difficulty', 'url', 'starter_code']
INFO:data_processing_optimized:Original APPS size: 5000
INFO:data_processing_optimized:Processed APPS columns: ['prompt', 'ground_truth']
INFO:data_processing_optimized:Processed APPS size: 50
INFO:data_processing_optimized:Loading APPS dataset from apps_cccs.json...
INFO:data_processing_optimized:Original APPS size: 7413
INFO:data_processing_optimized:Difficulty score range: 42.8 (easiest) to 6260.4 (hardest)
INFO:data_processing_optimized:Processed APPS columns: ['prompt', 'ground_truth', 'inputs', 'outputs']
INFO:data_processing_optimized:Processed APPS size: 74
INFO:__main__:MBPP dataset size: 9
INFO:__main__:APPS dataset size: 50
INFO:__main__:Skipping SFT warmup, using base model for GRPO
INFO:__main__:==================================================
INFO:__main__:Starting GRPO Training
INFO:__main__:==================================================
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
  9%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                                      | 20/222 [03:40<43:28, 12.91s/it]Traceback (most recent call last):
{'loss': 0.0836, 'grad_norm': 0.0, 'learning_rate': 9.594594594594594e-07, 'num_tokens': 3854.0, 'completions/mean_length': 129.2, 'completions/min_length': 66.0, 'completions/max_length': 192.4, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 86.8, 'completions/min_terminated_length': 66.0, 'completions/max_terminated_length': 107.6, 'rewards/unit_test_reward_function/mean': -0.41933332234621046, 'rewards/unit_test_reward_function/std': 0.39692260771989823, 'reward': -0.41933332234621046, 'reward_std': 0.39692260771989823, 'frac_reward_zero_std': 0.5, 'entropy': 1.3561277627944945, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.14}
{'loss': 0.0635, 'grad_norm': 0.0, 'learning_rate': 9.144144144144143e-07, 'num_tokens': 8448.0, 'completions/mean_length': 143.2, 'completions/min_length': 87.3, 'completions/max_length': 199.1, 'completions/clipped_ratio': 0.4, 'completions/mean_terminated_length': 67.45, 'completions/min_terminated_length': 61.7, 'completions/max_terminated_length': 73.2, 'rewards/unit_test_reward_function/mean': -0.4442916616797447, 'rewards/unit_test_reward_function/std': 0.17330008503049613, 'reward': -0.4442916616797447, 'reward_std': 0.17330008503049613, 'frac_reward_zero_std': 0.7, 'entropy': 1.3959372341632843, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.27}
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single_optimized.py", line 414, in <module>
    main()
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single_optimized.py", line 394, in main
    run_grpo_training(
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single_optimized.py", line 275, in run_grpo_training
    trainer.train()
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2316, in train
    return inner_training_loop(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 4014, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1067, in _prepare_inputs
    generation_batch = self._generate_and_score_completions(generation_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1462, in _generate_and_score_completions
    self._generate(prompts)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1400, in _generate
    prompt_ids, completion_ids, logprobs, extra_fields = self._generate_single_turn(prompts)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1375, in _generate_single_turn
    prompt_completion_ids = unwrapped_model.generate(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2779, in _sample
    while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2597, in _has_unfinished_sequences
    elif this_peer_finished:
KeyboardInterrupt
Traceback (most recent call last):
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single_optimized.py", line 414, in <module>
    main()
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single_optimized.py", line 394, in main
    run_grpo_training(
  File "/hdd3/albertwu/mini_rlvr/train_grpo_single_optimized.py", line 275, in run_grpo_training
    trainer.train()
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2316, in train
    return inner_training_loop(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/trainer.py", line 4014, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1067, in _prepare_inputs
    generation_batch = self._generate_and_score_completions(generation_batch)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1462, in _generate_and_score_completions
    self._generate(prompts)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1400, in _generate
    prompt_ids, completion_ids, logprobs, extra_fields = self._generate_single_turn(prompts)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1375, in _generate_single_turn
    prompt_completion_ids = unwrapped_model.generate(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2779, in _sample
    while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):
  File "/hdd3/albertwu/miniconda3/envs/rlvr/lib/python3.10/site-packages/transformers/generation/utils.py", line 2597, in _has_unfinished_sequences
    elif this_peer_finished:
KeyboardInterrupt
